---
title: "Group Project"
author: "A3"
date: '2022-08-03'
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)

library(GGally)
library(sandwich)
library(rgl)
library(leaps)
library(lmtest)
library(knitr)
library(modelsummary)
library(kableExtra)
library(gt)
```

## Introduction


With increasingly unaffordable housing having become a chronic social issue in Canada over the last two decades, the factors that contribute to rising housing cost have been in focus, and hotly debated among policy makers and voters alike. Here, we would like to measure the relative importance of the commonly referred contributors of rising cost of housing: interest rate, immigration, earnings increases, and general increase in consumer prices. We will explore and quantify the significance of the predictors or drivers of rising housing price above. Furthermore, by better understanding possible causes and predictors of the present day problem, we aim to better inform policymakers and their electorate on the most important issues underlying the unaffordable housing markets of the metropolitan Canada.


TODO: we need some references for this introduction.



### Variables

|     Name    |                                                               Description                                                                  |   Unit   |
|:--------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------:|:--------:|
| New Housing Price Index (y)     | Monthly series that measure changes over time of the selling prices of new residential houses sold by builders in the Canadian metropolitan areas. The reference period is December 2006, for which the index value is set to 100. | -        |
| Mortgage Rate ($x_1$) | Average annual mortgage lending rate for 5-year term. | %        |
| Immigrants ($x_2$) | Population growth due to the total number of immigrants to Canada between the preceding two calendar years. Immigration, Refugees and Citizenship Canada does not make immigration data with higher frequency than yearly. | -        |
| Average Weekly Earnings ($x_3$) | Average weekly earnings for all employees in Canada in Canadian dollar per week. | CAD/week |
| Consumer Price Index ($x_4$) | Indicator for changes in consumer prices of all goods and services experienced by Canadians. The time base is the period for which the CPI equals 100; currently this is the year 2002. | -        |

## Analysis

``` {r,echo=FALSE, warning=FALSE}
dataset <- read.csv("dataset.csv")
date <- as.Date(paste(dataset$Date,"-01",sep=""))
# dataset$Date <- as.numeric(date - min(date))
dataset$Date <- NULL
```



```{r, echo=FALSE}
plot(date, dataset$NHPI, main="Line graph of Monthly NHPI",
  xlab="Date", ylab="NHPI", type = 'l',
  )
```
```{r, echo=FALSE}
plot(dataset$CPI, dataset$NHPI, main="Scatterplot of NHPI against CPI", 
  xlab="CPI", ylab="NHPI",
  )
```

```{r, echo=FALSE}
plot(date, dataset$CPI, main="CPI Over Time",
  ylab="CPI", xlab="Time (monthly)", type = "l"
  )
```




```{r, echo=FALSE}
plot(dataset$Interest, dataset$NHPI, main="Scatterplot of NHPI against 5-Year Mortgage Rate",
  xlab="Mortgage Rate (%)", ylab="NHPI",
  )
```

TODO: explain why we need to transform Mortgage Rate based on this. It seems like a quadratic curve centered around 7. Defend it based on the correlations against NHPI as well.

|  Transformation  | Sample correlation (r) |
|:----------------:|:----------------------:|
|    $\text{Interest}$    |  `r cor(dataset$NHPI, dataset$Interest)`          |
| $log(\text{Interest})$  |  `r cor(dataset$NHPI, log(dataset$Interest))`     |
| $\text{Interest}^2$     |  `r cor(dataset$NHPI, dataset$Interest^2)`        |
| $(\text{Interest}-7)^2$ |  `r cor(dataset$NHPI, (dataset$Interest-7)^2)`    |

Table ?: Correlation between NHPI and Different Transformations of Interest




```{r, echo=FALSE}
plot(date, dataset$Interest, main="5-Year Mortgage Rate Over Time",
  ylab="Mortgage Rate (%)", xlab="Time (monthly)", type = "l"
  )
```

Because interest rates are mostly set by the Bank of Canada, the changes appear somewhat erratic.












```{r, echo=FALSE}
plot(dataset$Immigrants, dataset$NHPI, main="Scatterplot of NHPI against Population Growth due to Immigration", 
  xlab="Population Growth due to Immigration between Two Preceding Calendar Years", ylab="NHPI",
  )
```


```{r, echo=FALSE}
plot(date, dataset$Immigrants, main="Population Increase Due to Immigrations between Preceding Two years",
  ylab="Immigrants", xlab="Time (monthly)", type = "l"
  )
```

Due to the lack of monthly data on immigration provided by Statistics Canada, the data was imputed by applying the yearly data flatly across calendar years. The predictor variable itself doesn't have a strong linear pattern, but seems to have been generally increasing over the last two decades.


```{r, echo=FALSE}
plot(dataset$Earnings, dataset$NHPI, main="Scatterplot of NHPI against Average Weekly Employee Earnings",
  xlab="Average Weekly Employee Earnings", ylab="NHPI",
  )
```

We observe a sudden jump in the earnings. The jump happened in March 2020, and is likely due to the pandemic. 
TODO: Maybe highlight the pandemic era data with a different color.
TODO: Add a reference about the wage jump at the time if possible.

```{r, echo=FALSE}
plot(date, dataset$Earnings, main="Average Weekly Employee Earnings Over Time",
  ylab="Average Weekly Employee Earnings", xlab="Time (monthly)", type = "o"
  )
```


```{r, echo=FALSE}
# plot3d(z = dataset$NHPI, y = dataset$Earnings, x = date)

```

### Collinearity

We measured the collinearity with VIF.

```{r, echo=FALSE, echo=FALSE}
# plot(dataset)
ggpairs(data = dataset, cardinality_threshold=NULL)
```

```{r, echo=FALSE}
model.fl <- lm(NHPI ~ ., dataset)
vif <- data.frame(VIF=round(car::vif(model.fl),3))
kable(vif) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

TODO: explain the significance of VIF. VIF > 10 means collinearity may be a problem. The collinearity involving Earnings and CPI was addressed using an interaction term between Earnings and CPI.


### Transformation

TODO: justify based on the Q-Q plots of the fully linear model, and the model with an interaction term.


An interaction terms is added to our model to address the high collinearity of CPI and Earnings.



### Model Selection with Exhaustive Search


```{r, echo=FALSE}
subsets_models <- regsubsets(NHPI ~ . + CPI * Earnings + I(Interest^2), data = dataset, method="exhaustive") 
best_subsets <- summary(subsets_models)
```

```{r, echo=FALSE}
plot(best_subsets$cp, pch = 19, xlab = "Number of Variables", 
		 ylab = "Cp")
abline(0,1, col='red')
```


TODO: summary of exhaustive search result as a table of number of variables, variables, $R^2$, $R^2_{adj}$ and $C_p$. You can get them from the following.
```{r, echo=FALSE, results='hide'}
kable(best_subsets$which) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```
```{r, echo=FALSE}
model.fl.df <- data.frame(p=seq(0,length(best_subsets$rsq)-1,1), rsq=best_subsets$rsq, adjr2=best_subsets$adjr2, cp=best_subsets$cp)
colnames(model.fl.df) <- c("p", "$r^2$", "$r^2_{adj}$", "$C_p$")
kable(model.fl.df) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

We chose the model with 6 predictor variables including the interaction term and the quadratic term because $C_5$ is very close to the corresponding value of $p$. TODO: explain the importance of this. The model is accurate and unbiased and such.



We test 3 models.
A full linear model, a model with an interaction term between CPI and average weekly earnings, and a model with the same interaction term and a quadratic term for the mortgage rate. The quadratic term was added based on Figure 2, and the residual plots of the fully linear model, and the model with an interaction term.

```{r, echo=FALSE}
model.fl <- lm(NHPI ~ ., dataset)
model.interaction <- lm(NHPI ~ . + CPI*Earnings, dataset)
model.quad <- lm(NHPI ~ . + CPI*Earnings + I(Interest^2), dataset)
```

```{r, echo=FALSE}
models <- list(
  "Fully Linear"     = model.fl,
  "With an Interaction" = model.interaction,
  "Quadratic"     = model.quad
)

modelsummary(models, fmt = 5)
```

```{r, echo=FALSE}
kable(coef(summary(model.fl))) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```



```{r, echo=FALSE}
kable(coef(summary(model.interaction))) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```



```{r, echo=FALSE}
kable(coef(summary(model.quad))) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```



TODO: make a note on the Adjusted R-squared. It's the largest for the quadratic model.


### Serial Correlation

The standard assumptions of linear regression includes serial independence of data. The Durbin-Watson statistic was used to measure the serial correlation of our model [[2]](#references).

```{r, echo=FALSE}

dw <- dwtest(formula = NHPI ~ . + CPI * Earnings + I(Interest^2), data = dataset)
```
The Durbin-Watson statistic for our model is `r dw$statistic`, and which is close to 0 with a very small $p$ value, indicating high positive serial correlation. The standard errors of coefficients are underestimated if the data is positively serially correlated.


### Newey-West Standard Errors

The standard errors of coefficients are underestimated due to the high serial correlation. Instead the Newey-West standard errors, both Heteorscedasticity and Autocorrelation (HAC), should be used instead [[1]](#references). The chosen delay truncation value is 12 intervals (months).


```{r, echo=FALSE, results='hide'}
nw.fl <- NeweyWest(model.fl, lag=12, prewhite=FALSE, adjust=TRUE, verbose=TRUE)
nw.fl.coef <- as.data.frame(coeftest(model.fl, vcov.=nw.fl)[, ])
```
```{r, echo=FALSE}
kable(nw.fl.coef) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
``` 

The significance of some of the variables appear lower, and most of them appear insignificant when corrected for serial correlation.


```{r, echo=FALSE, results='hide'}
nw.inter <- NeweyWest(model.interaction, lag=12, prewhite=FALSE, adjust=TRUE, verbose=TRUE)
nw.inter.coef <- as.data.frame(coeftest(model.interaction, vcov.=nw.inter)[, ])
```
```{r, echo=FALSE}
kable(nw.inter.coef) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

When the interaction term is included, the significance of the predictor variables are preserved.




```{r, echo=FALSE, results='hide'}
nw.quad <- NeweyWest(model.quad, lag=12, prewhite=FALSE, adjust=TRUE, verbose=TRUE)
nw.quad.coef <- as.data.frame(coeftest(model.quad, vcov.=nw.quad)[, ])
```
```{r, echo=FALSE}
kable(nw.quad.coef) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```


The predictor variables remain significant even after the correction. The lag is set at 11 months. The effect of the interest rate is the least significant.




### Residuals


TODO: summarize the final linear model. Make a note on the interaction between CPI and Earnings being significant. The coefficient for the interaction is negative, which means the positive impact of earnings and CPI on NHPI is attenuated when these values changes in the same direction. In other words, if changes in average wage stay in parity with CPI, housing prices tend to be a little lower.


```{r, echo=FALSE}
plot(dataset$NHPI, model.fl$residuals, main="Residual plot for fully linear model",
  xlab="Fitted Values", ylab="Residuals")
```


```{r, echo=FALSE}
plot(dataset$NHPI, model.interaction$residuals, main="Residual plot for model with interaction",
  xlab="Fitted Values", ylab="Residuals")
```

```{r, echo=FALSE}
plot(dataset$NHPI, model.quad$residuals, main="Residual plot for quadratic model with interaction",
  xlab="Fitted Values", ylab="Residuals")
```

TODO: Is there a pattern? It seems we cannot explain with all variance in NHPI with the predictors here. We may need more variables for a more complete model.


```{r, echo=FALSE}
qqnorm(model.fl$residuals, frame = FALSE)
qqline(model.fl$residuals, col = "steelblue")

```

The error distribution of the fully linear model is light-tailed, and the normality-of-errors assumption may not hold. While The simplicity of the model is a positive attribute, the model is too light-tailed on the right side, and undermines the model's value for making forecasts.


```{r, echo=FALSE}
qqnorm(model.interaction$residuals, frame = FALSE)
qqline(model.interaction$residuals, col = "steelblue")

```



```{r, echo=FALSE}
qqnorm(model.quad$residuals, frame = FALSE)
qqline(model.quad$residuals, col = "steelblue")

```

The distribution of the residual is heavy-tailed, but not extremely so. The normal error assumption seems to mostly hold.


### Forecast Tests with a Holdout Set
We cannot do a cross-validation on a time series data. We instead train our model on the first 80% of the data, and test it on the last 20% of the data. The root mean square prediction errors are used to evaluate the three models. But this may not be an effective way to evaluate the model involving a time series.


```{r, echo=FALSE}
train <- 1:as.integer(dim(dataset)[1]*.8)
model.names <- c('Fully linear', 'With an Interaction', 'Quadratic')

rmse <- data.frame(Model=model.names, RMSE=c(0,0,0))

reg <- lm(NHPI ~ . , dataset[train,])
rmse$RMSE[1] <- sqrt(sum((dataset$NHPI[-train] - predict(reg, dataset[-train,]))^2))/length(dataset$NHPI[-train])
```

```{r, echo=FALSE}
reg <- lm(NHPI ~ . + CPI*Earnings, dataset[train,])
rmse$RMSE[2] <- sqrt(sum((dataset$NHPI[-train] - predict(reg, dataset[-train,]))^2))/length(dataset$NHPI[-train])
```

```{r, echo=FALSE}
reg <- lm(NHPI ~ . + CPI*Earnings + I(Interest^2), dataset[train,])
rmse$RMSE[3] <- sqrt(sum((dataset$NHPI[-train] - predict(reg, dataset[-train,]))^2))/length(dataset$NHPI[-train])
```

```{r, echo=FALSE}
kable(rmse) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

The model with an interaction term seems to perform the best. However, our data is a time series, and the holdout sets necessarily include the most recent data, which tend to be the most important data points in time series models. Furthermore, because the most recent data involves the highly unusually period of the COVID-19 pandemic, it is unlikely that we can build a strong model while excluding the most recent 20% .



### Akaike Information Criterion (AIC)

Because of the reasons discussed in the previous sections, tests using holdout sets may be misleading in evaluating the models. As a result, AIC is particularly valuable for choosing the best model among our three models.

```{r, echo=FALSE}
kable(data.frame(Model=model.names, AIC=c(AIC(model.fl), AIC(model.interaction), AIC(model.quad)))) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F)
```

TODO: I am not too sure about the wording here.

The quadratic model has the lowest AIC among the three models. It implies that the quadratic model has the smallest prediction error in general.



### Forecasts Using Models

One major use of time series models is to forecast response variables in the future. In this section, we attempt to forecast NHPI for June and July 2022 with imputed values.
The real NHPI for June 2022 was 125.9 [[4]](#references). The NHPI for July 2022 has not been published yet.

```{r, echo=FALSE}
# modified to produce a prediction interval
predict.interval <- function(x, covm, newdata){
    tt <- delete.response(terms(x))
    m.mat <- model.matrix(tt, data=newdata)
    m.coef <- x$coef
    fit <- as.vector(m.mat %*% x$coef)
    se <- sqrt(diag(m.mat%*%covm%*%t(m.mat)))
    
    interval <- c(-1,1) * se * qt(.975, length(dataset$NHPI) - 5 - 1) + fit
    
    return(data.frame(lower=interval[1], fit=fit, upper=interval[2], se=se))
  }

# June
predict.interval(model.quad, nw.quad, data.frame(CPI=152.9, Immigrants=226203, Earnings=1159.85, Interest=1.75))

# July with imputed CPI and Earnings (assuming all predictor variables stay the same except for the interest rate)
predict.interval(model.quad, nw.quad, data.frame(CPI=155.9, Immigrants=226203, Earnings=1159.85, Interest=2.75))

```


```{r, echo=FALSE}
# June
predict.interval(model.fl, nw.fl, data.frame(CPI=152.9, Immigrants=226203, Earnings=1159.85, Interest=1.75))

# July with imputed CPI and Earnings (assuming all predictor variables stay the same except for the interest rate)
predict.interval(model.fl, nw.fl, data.frame(CPI=155.9, Immigrants=226203, Earnings=1159.85, Interest=2.75))
```


```{r, echo=FALSE}
# June
predict.interval(model.interaction, nw.inter, data.frame(CPI=152.9, Immigrants=226203, Earnings=1159.85, Interest=1.75))

# July with imputed CPI and Earnings (assuming all predictor variables stay the same except for the interest rate)
predict.interval(model.interaction, nw.inter, data.frame(CPI=155.9, Immigrants=226203, Earnings=1159.85, Interest=2.75))
```

TODO: The forecasts cannot be directly compared evaluated on the prediction errors. So focus on the standard errors instead.





## Discussion

The minimum in the quadratic model is at $Interest = \frac{-b_{Interest}}{2 \cdot b_{Interest^2}}$. Note that $b_{Interest^2}$ positive.

```{r, echo=FALSE}
b_Interest <- model.quad$coefficients['Interest']
b_Interest2 <- model.quad$coefficients['I(Interest^2)']

interest.at.min <- -b_Interest / (2 * b_Interest2)
```
The model suggests the 5-year mortgage rate to achieve the minimum NHPI is `r round(interest.at.min, 3)` % if all other predictor variables are held constant. The positive correlation is unintuitive as home price is expected to continue to decline with higher interest rates. This does not necessarily mean the model is biased. There have been periods of rapidly rising NHPI through interest hikes in the 80's and 2000's. **TODO: refer to the figure below.**  However, the mortgage rate at the partial minimum is close to the historic low of `r min(dataset$Interest)`%, and may imply a bias due to a limited range of interest rates in the data.  We should also consider the fact that interest rates are largely controlled by the Bank of Canada, and are raised in response rising costs including housing costs. **TODO: Please find a reference for this.** Furthermore, the effects of raising interest rates to housing cost may come with significant delays. Hence, high interest rates past a threshold may be associated with high home price, and our quadratic model may reflect such tendencies. In future studies, we could explore the possible causal effect of interest rates on housing prices by introducing delays to interest rates.

```{r, echo=FALSE}
historical <- read.csv('historical.csv')
historical$Date <- as.Date(paste(historical$Date,"-01",sep=""))
```

```{r, echo=FALSE}
ggplot(historical, aes(Date, text="Date (monthly)")) + 
  ggtitle("Historical NHPI and 5-Year Mortgage Rate") + theme(plot.title = element_text(hjust = 0.5)) +
  geom_line(aes(y = NHPI, colour = "NHPI")) + 
  geom_line(aes(y = Interest*10, colour = "5-Year Mortgage Rate")) + 
  scale_y_continuous(
    "NHPI", 
    sec.axis = sec_axis(~ . / 10, name = "5-Year Mortgage Rate (%)")
  )
```

TODO: Given the 

TODO: choose the final model.


TODO: Summarize the final model. Use the results from coeftest.



## Conclusion

TODO: Which was the most significant predictor? The government can directly control the interest rate, and immigration. It can also affect average earnings to some degree. Which one would be the best way to lower housing price if political considerations were not a concern? Can we predict the price trend in the future based on the Bank of Canada's recent decisions to increase the interest rate?

When adjusted for CPI and earnings, immigration and the interest rate seem to affect the NHPI in the opposite directions that they are typically associated with in the literature. High immigration lowers NHPI, and high interest rate is associated with high NHPI. The population increase due to immigration is the least significant predictor of NHPI in our model. 



## References

Newey, Whitney K; West, Kenneth D (1987). "A Simple, Positive Semi-definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix" (PDF). Econometrica. 55 (3): 703–708. doi:10.2307/1913610. JSTOR 1913610.

Durbin, J.; Watson, G. S. (1971). "Testing for serial correlation in least squares regression.III". Biometrika. 58 (1): 1–19. doi:10.2307/2334313

Statistics Canada. Table 10-10-0122-01  Financial market statistics, last Wednesday unless otherwise stated, Bank of Canada 
https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1010012201

Statistics Canada. Table 18-10-0205-01  New housing price index, monthly 
https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1810020501

Statistics Canada. Table 34-10-0145-01  Canada Mortgage and Housing Corporation, conventional mortgage lending rate, 5-year term 
https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=3410014501

Statistics Canada. Table 17-10-0008-01  Estimates of the components of demographic growth, annual 
https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1710000801

Statistics Canada. Table 18-10-0004-01  Consumer Price Index, monthly, not seasonally adjusted 
https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1810000401

Statistics Canada. Table 14-10-0223-01  Employment and average weekly earnings (including overtime) for all employees by province and territory, monthly, seasonally adjusted 
https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1410022301
